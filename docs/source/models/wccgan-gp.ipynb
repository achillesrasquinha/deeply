{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3539db47",
   "metadata": {},
   "source": [
    "# Wasserstein Deep Convolutional Conditional Generative Adversarial Network (with Gradient Penalty) (WDCCGAN-GP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4471ba2",
   "metadata": {},
   "source": [
    "A model skeleton for Wasserstein Deep Convolutional Generative Adversarial Networks (with Gradient Penalty) (WDCCGAN-GP)s. It was first introduced in the paper titled *[Improved Training of Wasserstein GANs](https://arxiv.org/abs/1704.00028)* by Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, Aaron Courville."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad94ee",
   "metadata": {},
   "source": [
    "## usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0e7c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeply\n",
    "import deeply.datasets as dd\n",
    "from deeply.transformers.scaler import image_scaler\n",
    "\n",
    "mnist, info = dd.load(\"mnist\", shuffle_files = True, as_supervised = True, with_info = True)\n",
    "image_shape = info.features[\"image\"].shape\n",
    "n_classes   = info.features[\"label\"].num_classes\n",
    "\n",
    "gan = deeply.hub(\"wdcgan-gp\", input_shape = image_shape, n_classes = n_classes,\n",
    "                 decoder_batch_norm = True, encoder_dropout_rate = 0.3,\n",
    "                 encoder_layer_growth_rate = 2, scaler = image_scaler,\n",
    "                 init_decoder_units = 256, decoder_layer_growth_rate = 0.5, kernel_size = 5,\n",
    "                 decoder_strides  = [1, 2], final_activation = \"tanh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976cd6ac",
   "metadata": {},
   "source": [
    "## example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f1ae69c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from deeply.plots import imgplot as imgplt, mplt\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "def mapper(image, label):\n",
    "    return image_scaler.fit_transform(image), tf.one_hot(label, n_classes)\n",
    "\n",
    "config = dict(batch_size = 256,\n",
    "              epochs = 20)\n",
    "batch_size = config[\"batch_size\"]\n",
    "\n",
    "data   = mnist[\"train\"].map(mapper)\n",
    "batch  = data.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d21a745",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012476921081542969,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 21,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 20,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62647910cb9f430c9f5a4e1694d7ee5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 19:08:28.013929: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.07780289649963379,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 21,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 235,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89a6aec94334cd49a518b16659b1b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 19:08:28.244984: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/achillesrasquinha/miniforge3/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/achillesrasquinha/miniforge3/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/achillesrasquinha/miniforge3/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/achillesrasquinha/dev/deeply/src/deeply/model/gan.py\", line 183, in train_step\n        loss_discriminator = loss_discriminator + self._compute_gradient_penalty(data_feed, generated_output) * self.grad_weight\n    File \"/Users/achillesrasquinha/dev/deeply/src/deeply/model/gan.py\", line 97, in _compute_gradient_penalty\n        diff  = fake_output - real_output\n\n    ValueError: Dimensions must be equal, but are 256 and 512 for '{{node sub}} = Sub[T=DT_FLOAT](wdcgan-gp-generator/output/activation_batch_norm_dropout_13/activation_1/Tanh, concat_3)' with input shapes: [256,28,28,1], [512,28,28,11].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m trange(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m tqdm(batch):\n\u001b[0;32m----> 7\u001b[0m         history \u001b[38;5;241m=\u001b[39m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgan.h5d5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     save_img_samples(gan, samples \u001b[38;5;241m=\u001b[39m samples, to_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcgan.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/dev/deeply/src/deeply/model/gan.py:64\u001b[0m, in \u001b[0;36mGANModel.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# kwargs = update_kwargs(kwargs, {\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m#     \"callbacks\": {\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m#     }\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# })\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     super_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(GANModel, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msuper_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/deeply/src/deeply/model/base.py:34\u001b[0m, in \u001b[0;36mBaseModel.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m get_fit_args_kwargs(\u001b[38;5;28mself\u001b[39m, args, kwargs, custom \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\n\u001b[1;32m     31\u001b[0m })\n\u001b[1;32m     33\u001b[0m super_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(BaseModel, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msuper_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/x2/4k1n7c3d5zx3_5sp7x24yzzw0000gn/T/__autograph_generated_file0p_a8_zb.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/deeply/src/deeply/model/gan.py:183\u001b[0m, in \u001b[0;36mGANModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    180\u001b[0m         loss_discriminator \u001b[38;5;241m=\u001b[39m disc_loss(predictions, fake_output)\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_weight:\n\u001b[0;32m--> 183\u001b[0m             loss_discriminator \u001b[38;5;241m=\u001b[39m loss_discriminator \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_gradient_penalty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_output\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_weight\n\u001b[1;32m    185\u001b[0m discriminator_gradients \u001b[38;5;241m=\u001b[39m discriminator_tape\u001b[38;5;241m.\u001b[39mgradient(loss_discriminator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(discriminator_gradients, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "File \u001b[0;32m~/dev/deeply/src/deeply/model/gan.py:97\u001b[0m, in \u001b[0;36mGANModel._compute_gradient_penalty\u001b[0;34m(self, real_output, fake_output)\u001b[0m\n\u001b[1;32m     94\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(real_output)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     96\u001b[0m alpha \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal([batch_size, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m---> 97\u001b[0m diff  \u001b[38;5;241m=\u001b[39m \u001b[43mfake_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreal_output\u001b[49m\n\u001b[1;32m     98\u001b[0m interpolated \u001b[38;5;241m=\u001b[39m real_output \u001b[38;5;241m+\u001b[39m alpha \u001b[38;5;241m*\u001b[39m diff\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m gp_tape:\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/achillesrasquinha/miniforge3/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/achillesrasquinha/miniforge3/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/achillesrasquinha/miniforge3/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/achillesrasquinha/dev/deeply/src/deeply/model/gan.py\", line 183, in train_step\n        loss_discriminator = loss_discriminator + self._compute_gradient_penalty(data_feed, generated_output) * self.grad_weight\n    File \"/Users/achillesrasquinha/dev/deeply/src/deeply/model/gan.py\", line 97, in _compute_gradient_penalty\n        diff  = fake_output - real_output\n\n    ValueError: Dimensions must be equal, but are 256 and 512 for '{{node sub}} = Sub[T=DT_FLOAT](wdcgan-gp-generator/output/activation_batch_norm_dropout_13/activation_1/Tanh, concat_3)' with input shapes: [256,28,28,1], [512,28,28,11].\n"
     ]
    }
   ],
   "source": [
    "from deeply.model.gan import save_img_samples\n",
    "\n",
    "samples = gan.get_random_latent_vector(shape = (batch_size, None))\n",
    "\n",
    "for e in trange(config[\"epochs\"]):\n",
    "    for b in tqdm(batch):\n",
    "        history = gan.fit(b, batch_size = batch_size, checkpoint_path = \"gan.h5d5\")\n",
    "    save_img_samples(gan, samples = samples, to_file = \"cgan.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
